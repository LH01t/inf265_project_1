{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the same results with train and train_manual_update\n",
    "- Write torch.manual_seed(42) at the beginning of your notebook.\n",
    "- Write torch.set_default_dtype(torch.double) at the beginning of your notebook to alleviate precision errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "Load, analyse and preprocess the CIFAR-10 dataset. Split it into 3\n",
    "datasets: training, validation and test. Take a subset of these datasets\n",
    "by keeping only 2 labels: cat and car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar(train_val_split=0.9, data_path='../data/', preprocessor=None):\n",
    "    \"\"\"\n",
    "    Loads the dataset and split into train, test and val \\n\n",
    "    Keeps only the label \"cat\" and \"car\"\n",
    "    \"\"\"\n",
    "\n",
    "    # transformer to resize images to 16x16 pixels\n",
    "    if preprocessor is None:\n",
    "        preprocessor = transforms.Compose([\n",
    "            transforms.Resize(16),\n",
    "            transforms.ToTensor()\n",
    "            ])\n",
    "    \n",
    "    # load datasets\n",
    "    train_val_data = datasets.CIFAR10(data_path, train=True, download=True, transform=preprocessor)\n",
    "    test_data = datasets.CIFAR10(data_path, train=False, download=True, transform=preprocessor)\n",
    "    \n",
    "    # sizes of train and validation data\n",
    "    train_size = int(train_val_split * len(train_val_data))\n",
    "    val_size = len(train_val_data) - train_size\n",
    "\n",
    "    # split train_val_data into train and validation sets\n",
    "    train_data, val_data = random_split(train_val_data, [train_size, val_size])\n",
    "\n",
    "    # create subsets with only cat (0) and car (1)\n",
    "    label_map = {3: 0, 1: 1} \n",
    "\n",
    "    train = [(img, label_map[label]) for img, label in train_data if label in [1,3]]\n",
    "    val = [(img, label_map[label]) for img, label in val_data if label in [1,3]]\n",
    "    test = [(img, label_map[label]) for img, label in test_data if label in [1,3]]\n",
    "\n",
    "    return train, val, test\n",
    "\n",
    "\n",
    "def compute_accuracy(model, loader):\n",
    "    \"\"\"\n",
    "    Computes the accuracy of the given model on the given dataloader\n",
    "    \"\"\"\n",
    "    # set the model to evaluation mode\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # disable gradient tracking\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            # forward pass\n",
    "            outputs = model(images)\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            total += labels.size(0)\n",
    "            # compare predicted with labels\n",
    "            correct += torch.eq(predicted, labels).sum().item()\n",
    "\n",
    "    # calculate accuracy\n",
    "    accuracy = correct / total * 100.0\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset, create loss function and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "data_train, data_val, data_test = load_cifar()\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# create dataloaders using train, val and test sets\n",
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=64, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(data_val, batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(data_test, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize images and distribution of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_distribution(data, label_names=None):\n",
    "    \"\"\"\n",
    "    Plots the distribution of the given data across the labels\n",
    "    \"\"\"\n",
    "    # Extract labels from the dataset\n",
    "    labels = [label for _, label in data]\n",
    "    \n",
    "    # Calculate distribution using numpy\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    distribution = dict(zip(unique_labels, counts))\n",
    "    \n",
    "    # Map numeric labels to names if a mapping is provided\n",
    "    if label_names is not None:\n",
    "        x_labels = [label_names.get(label, label) for label in unique_labels]\n",
    "    else:\n",
    "        x_labels = unique_labels\n",
    "\n",
    "    # Visualize the label distribution using a bar chart\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(x_labels, counts, color='skyblue')\n",
    "    plt.xlabel('Labels')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Data Distribution')\n",
    "    plt.show()\n",
    "    \n",
    "    return distribution\n",
    "\n",
    "\n",
    "def visualize_random_images(data, num_images):\n",
    "    \"\"\"\n",
    "    Visualizes random images from the data\n",
    "    \"\"\"\n",
    "    samples = random.sample(data, num_images)\n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    \n",
    "    # Loop over the selected samples\n",
    "    for i, (img, label) in enumerate(samples):\n",
    "        plt.subplot(1, num_images, i+1)\n",
    "        \n",
    "        # If the image is a tensor, convert it to a numpy array for plotting.\n",
    "        if torch.is_tensor(img):\n",
    "            # Convert from (C, H, W) to (H, W, C)\n",
    "            img = img.permute(1, 2, 0).numpy()\n",
    "            \n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Label: {label}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 4529, 1: 4488}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data_distribution(data_train, {0: 'cat', 1: 'car'}))\n",
    "visualize_random_images(data_train, num_images=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a MyMLP class that implements a MLP in PyTorch (so only fully\n",
    "connected layers) such that:\n",
    "    \n",
    "    - The input dimension is 768(= 16 ∗ 16 ∗ 3) and the output dimension is 2 (for the 2 classes).\n",
    "    - The hidden layers have respectively 128 and 32 hidden units.\n",
    "    - All activation functions are ReLU. The last layer has no activation function since the cross-entropy loss already includes a softmax activation\n",
    "function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MyMLP Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(16*16*3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a train(n_epochs, optimizer, model, loss_fn, train_loader) function that trains model for n_epochs epochs given an optimizer optimizer, a loss function loss_fn and a dataloader train_loader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    \"\"\"\n",
    "    Trains a model for a given number of epochs using the optimizer, loss function and dataloader given\n",
    "    \"\"\"\n",
    "\n",
    "    n_batch = len(train_loader)\n",
    "    train_losses = []\n",
    "    # setting the model in train mode\n",
    "    model.train()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            \n",
    "            imgs.to(device=device, dtype=torch.double) \n",
    "            labels = labels.to(device=device)\n",
    "\n",
    "            # pass the image through the model and getting an output\n",
    "            outputs = model(imgs)\n",
    "\n",
    "            # compute the loss\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # compute the gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # zero out all gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        # compute the average loss for each epoch\n",
    "        train_losses.append(loss_train / n_batch)\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{}  |  Epoch {}  |  Training loss {:.3f}'.format(\n",
    "                datetime.now().time(), epoch, loss_train / n_batch))\n",
    "    \n",
    "    return train_losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a similar function train manual_update that has no optimizer parameter, but a learning rate lr parameter instead and that manually updates each trainable parameter of model using equation (2). Do not forget to zero out all gradients after each iteration. \n",
    "\n",
    "Train 2 instances of MyMLP, one using train and the other using train_manual_update (use the same parameter values for both models). Compare their respective training losses. To get exactly the same results with both functions, see section 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_manual_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_manual_update(n_epochs, model, loss_fn, train_loader, lr=1e-2, momentum_coeff=0., weight_decay=0.):\n",
    "    \"\"\"\n",
    "    Trains a model for a given number of epochs with the given loss function and dataloader. \\n\n",
    "    Manually updates each trainable parameter using the given learning rate, momentum and weight decay\n",
    "    \"\"\"\n",
    "    \n",
    "    n_batch = len(train_loader)\n",
    "    train_losses = []\n",
    "    # setting the model in train mode\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "\n",
    "    # dict for storing velocity values when using momentum\n",
    "    v = dict()\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, label in train_loader:\n",
    "            \n",
    "            # pass the image through the model and get an output\n",
    "            outputs = model(imgs)\n",
    "            # compute the loss and the gradients\n",
    "            loss = loss_fn(outputs, label)\n",
    "            loss.backward()\n",
    "\n",
    "            # update all parameters\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "\n",
    "                    # the gradient value \n",
    "                    g_t = p.grad\n",
    "\n",
    "                    # with weight decay\n",
    "                    if weight_decay != 0:\n",
    "                        # update the gradient value using the weight decay\n",
    "                        g_t += weight_decay * p.data\n",
    "\n",
    "                    # with momentum\n",
    "                    if momentum_coeff != 0: \n",
    "                        # set initial velocity to gradient for each parameter\n",
    "                        if p not in v:\n",
    "                            v[p] = g_t \n",
    "                        else:\n",
    "                            # update the velocity using the momentum, the stored velocity and gradient\n",
    "                            v[p] = (momentum_coeff * v[p]) + g_t\n",
    "\n",
    "                        # update the gradient value\n",
    "                        g_t = v[p]\n",
    "\n",
    "                    # compute new parameter value\n",
    "                    p.data -=  lr * g_t\n",
    "\n",
    "                # zero out the gradients\n",
    "                model.zero_grad()\n",
    "\n",
    "                loss_train += loss.item()\n",
    "\n",
    "        # compute the average loss for each epoch\n",
    "        train_losses.append(loss_train / n_batch)\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{}  |  Epoch {}  |  Training loss {:.3f}'.format(\n",
    "                datetime.now().time(), epoch, loss_train / n_batch))\n",
    "            \n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for comparing training losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_loss(train_losses, train_manual_losses):\n",
    "    \"\"\"\n",
    "    Compares two lists of losses and finds the max absolute difference\n",
    "    \"\"\"\n",
    "    max_diff = 0\n",
    "    for tl, tml in zip(train_losses, train_manual_losses):\n",
    "        # finding the absolute difference between train loss and manual loss\n",
    "        if abs(tl-tml) > max_diff:\n",
    "            max_diff = abs(tl-tml)\n",
    "\n",
    "    print(f\"Max absolute difference between training losses: {max_diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for comparing train() and train_manual_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_train_and_manual(train, train_man, added_text=\"\", weight_decay=0., momentum=0.):\n",
    "    \"\"\"\n",
    "    Trains models on two different training functions and compares the accuracy and loss with the given weight decay and momentum\n",
    "    \"\"\"\n",
    "    torch.manual_seed(42)\n",
    "    model = MyNet()\n",
    "\n",
    "    # creating an optimizer with the given hyperparameters\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-2, weight_decay = weight_decay, momentum = momentum)\n",
    "\n",
    "    # Training an instance of MyMLP using train (SGD optimizer)\n",
    "    print(f\"Training using SGD optimizer {added_text}:\\n\")\n",
    "    train_losses = train(\n",
    "        n_epochs = 30,\n",
    "        optimizer= optimizer, \n",
    "        model = model, \n",
    "        loss_fn = loss_fn, \n",
    "        train_loader = train_loader\n",
    "    )\n",
    "\n",
    "    # calculating training and validation accuracy\n",
    "    a_t = compute_accuracy(model, train_loader)\n",
    "    a_v = compute_accuracy(model, val_loader)\n",
    "    print(f\"\\nTraining accuracy: {a_t}\")\n",
    "    print(f\"Validation accuracy: {a_v}\")\n",
    "\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    model = MyNet()\n",
    "\n",
    "    # training an instance of MyMLP using train_manual_update with the given hyperparameters\n",
    "    print(f\"Training using manual update {added_text}:\\n\")\n",
    "    train_manual_losses = train_man(\n",
    "        n_epochs = 30,\n",
    "        model = model, \n",
    "        loss_fn = loss_fn, \n",
    "        train_loader = train_loader,\n",
    "        weight_decay = weight_decay,\n",
    "        momentum_coeff = momentum\n",
    "    )\n",
    "\n",
    "    # calculating training and validation accuracy\n",
    "    a_t = compute_accuracy(model, train_loader)\n",
    "    a_v = compute_accuracy(model, val_loader)\n",
    "    print(f\"\\nTraining accuracy: {a_t}\")\n",
    "    print(f\"Validation accuracy: {a_v}\")\n",
    "\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    # comparing the loss between the two methods\n",
    "    compare_loss(train_losses, train_manual_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) Training two models using train and train_manual_update and comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training using SGD optimizer :\n",
      "\n",
      "10:33:58.759371  |  Epoch 1  |  Training loss 0.683\n",
      "10:33:59.361653  |  Epoch 10  |  Training loss 0.445\n",
      "10:34:00.020270  |  Epoch 20  |  Training loss 0.349\n",
      "10:34:00.684949  |  Epoch 30  |  Training loss 0.285\n",
      "\n",
      "Training accuracy: 87.63446822668294\n",
      "Validation accuracy: 85.96134282807732\n",
      "--------------------------------------------------\n",
      "Training using manual update :\n",
      "\n",
      "10:34:00.796368  |  Epoch 1  |  Training loss 0.683\n",
      "10:34:01.455880  |  Epoch 10  |  Training loss 0.445\n",
      "10:34:02.174104  |  Epoch 20  |  Training loss 0.349\n",
      "10:34:02.949643  |  Epoch 30  |  Training loss 0.285\n",
      "\n",
      "Training accuracy: 87.63446822668294\n",
      "Validation accuracy: 85.96134282807732\n",
      "--------------------------------------------------\n",
      "Max absolute difference between training losses: 2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "compare_train_and_manual(train, train_manual_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) Training two models using train and train_manual_update with L2 regularization and comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training using SGD optimizer with weight decay:\n",
      "\n",
      "10:34:03.077861  |  Epoch 1  |  Training loss 0.683\n",
      "10:34:03.751507  |  Epoch 10  |  Training loss 0.446\n",
      "10:34:04.478812  |  Epoch 20  |  Training loss 0.351\n",
      "10:34:05.244430  |  Epoch 30  |  Training loss 0.288\n",
      "\n",
      "Training accuracy: 87.54574692247976\n",
      "Validation accuracy: 86.46998982706002\n",
      "--------------------------------------------------\n",
      "Training using manual update with weight decay:\n",
      "\n",
      "10:34:05.349426  |  Epoch 1  |  Training loss 0.683\n",
      "10:34:06.062080  |  Epoch 10  |  Training loss 0.446\n",
      "10:34:06.860805  |  Epoch 20  |  Training loss 0.351\n",
      "10:34:07.655223  |  Epoch 30  |  Training loss 0.288\n",
      "\n",
      "Training accuracy: 87.54574692247976\n",
      "Validation accuracy: 86.46998982706002\n",
      "--------------------------------------------------\n",
      "Max absolute difference between training losses: 1.1102230246251565e-16\n"
     ]
    }
   ],
   "source": [
    "compare_train_and_manual(train, train_manual_update, \"with weight decay\", weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (7) Training two models using train and train_manual_update with momentum and comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training using SGD optimizer with momentum:\n",
      "\n",
      "10:34:07.779542  |  Epoch 1  |  Training loss 0.573\n",
      "10:34:08.669606  |  Epoch 10  |  Training loss 0.273\n",
      "10:34:09.483926  |  Epoch 20  |  Training loss 0.212\n",
      "10:34:10.213954  |  Epoch 30  |  Training loss 0.174\n",
      "\n",
      "Training accuracy: 92.96883664189863\n",
      "Validation accuracy: 89.11495422177009\n",
      "--------------------------------------------------\n",
      "Training using manual update with momentum:\n",
      "\n",
      "10:34:10.321983  |  Epoch 1  |  Training loss 0.573\n",
      "10:34:11.084675  |  Epoch 10  |  Training loss 0.273\n",
      "10:34:12.013497  |  Epoch 20  |  Training loss 0.212\n",
      "10:34:12.919148  |  Epoch 30  |  Training loss 0.174\n",
      "\n",
      "Training accuracy: 92.96883664189863\n",
      "Validation accuracy: 89.11495422177009\n",
      "--------------------------------------------------\n",
      "Max absolute difference between training losses: 3.3306690738754696e-16\n"
     ]
    }
   ],
   "source": [
    "compare_train_and_manual(train, train_manual_update, \"with momentum\", momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (8-9) Testing different hyperparameter values and selecting the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders using train and validation sets\n",
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(data_val, batch_size=64, shuffle=False)\n",
    "\n",
    "def hyperparameter_testing():\n",
    "    \"\"\"\n",
    "    Finding the best hyperparameters by training models on different combinations of hyperparameters \\n\n",
    "    Choosing the best model based on the validation accuracy\\n\n",
    "    Returning a dictionary with the best model with the chosen hyperparameters\n",
    "    \"\"\"\n",
    "\n",
    "    best_settings = {\"Model\": None,\n",
    "                     \"Accuracy\": 0,\n",
    "                     \"Momentum\": 0,\n",
    "                     \"Weight decay\": 0, \n",
    "                     \"Learning rate\": 0\n",
    "                    }\n",
    "\n",
    "    epochs = 35\n",
    "    momentum = [0, 0.85, 0.9]\n",
    "    w_decay = [0, 0.001, 0.01]\n",
    "    learning_rate = [0.001, 0.01]\n",
    "\n",
    "    print(\"\\nTrain manual update:\")\n",
    "\n",
    "    hyperparameter_values = list(itertools.product(learning_rate, momentum, w_decay))\n",
    "    for lr, m, wd in hyperparameter_values:\n",
    "\n",
    "        # create new model for each new combination of hyperparameters\n",
    "        torch.manual_seed(42)\n",
    "        model = MyNet().to(device=device)\n",
    "\n",
    "        print(f\"Momentum: {m} \\nWeight decay: {wd} \\nLearning rate: {lr}\")\n",
    "        # train model with the given hyperparameters\n",
    "        train_manual_update(\n",
    "            n_epochs = epochs,\n",
    "            model = model,  \n",
    "            loss_fn = loss_fn, \n",
    "            train_loader = train_loader,\n",
    "            lr = lr,\n",
    "            momentum_coeff=m,\n",
    "            weight_decay=wd \n",
    "        )\n",
    "        \n",
    "        # compute validation accuracy\n",
    "        a = compute_accuracy(model, val_loader)\n",
    "        print(f\"\\nValidation accuracy: {a}\")\n",
    "        print(\"-\"*50)\n",
    "\n",
    "        # choose best model according to accuracy (sett dette utfor så man trener først så velger beste modell)\n",
    "        if a > best_settings[\"Accuracy\"]:\n",
    "            best_settings[\"Model\"] = model\n",
    "            best_settings[\"Accuracy\"] = a\n",
    "            best_settings[\"Momentum\"] = m\n",
    "            best_settings[\"Weight decay\"] = wd\n",
    "            best_settings[\"Learning rate\"] = lr\n",
    "    \n",
    "    return best_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train manual update:\n",
      "Momentum: 0 \n",
      "Weight decay: 0 \n",
      "Learning rate: 0.001\n",
      "10:34:13.077714  |  Epoch 1  |  Training loss 0.695\n",
      "10:34:13.802949  |  Epoch 10  |  Training loss 0.669\n",
      "10:34:14.663078  |  Epoch 20  |  Training loss 0.625\n",
      "10:34:15.512557  |  Epoch 30  |  Training loss 0.565\n",
      "\n",
      "Validation accuracy: 72.63479145473042\n",
      "--------------------------------------------------\n",
      "Momentum: 0 \n",
      "Weight decay: 0.001 \n",
      "Learning rate: 0.001\n",
      "10:34:16.015703  |  Epoch 1  |  Training loss 0.695\n",
      "10:34:16.839567  |  Epoch 10  |  Training loss 0.669\n",
      "10:34:17.898371  |  Epoch 20  |  Training loss 0.626\n",
      "10:34:18.734397  |  Epoch 30  |  Training loss 0.566\n",
      "\n",
      "Validation accuracy: 72.53306205493388\n",
      "--------------------------------------------------\n",
      "Momentum: 0 \n",
      "Weight decay: 0.01 \n",
      "Learning rate: 0.001\n",
      "10:34:19.259175  |  Epoch 1  |  Training loss 0.695\n",
      "10:34:20.014908  |  Epoch 10  |  Training loss 0.670\n",
      "10:34:20.862348  |  Epoch 20  |  Training loss 0.631\n",
      "10:34:21.683734  |  Epoch 30  |  Training loss 0.574\n",
      "\n",
      "Validation accuracy: 72.02441505595118\n",
      "--------------------------------------------------\n",
      "Momentum: 0.85 \n",
      "Weight decay: 0 \n",
      "Learning rate: 0.001\n",
      "10:34:22.169824  |  Epoch 1  |  Training loss 0.688\n",
      "10:34:22.969103  |  Epoch 10  |  Training loss 0.471\n",
      "10:34:23.864859  |  Epoch 20  |  Training loss 0.406\n",
      "10:34:24.744398  |  Epoch 30  |  Training loss 0.332\n",
      "\n",
      "Validation accuracy: 85.14750762970499\n",
      "--------------------------------------------------\n",
      "Momentum: 0.85 \n",
      "Weight decay: 0.001 \n",
      "Learning rate: 0.001\n",
      "10:34:25.330805  |  Epoch 1  |  Training loss 0.688\n",
      "10:34:26.199922  |  Epoch 10  |  Training loss 0.472\n",
      "10:34:27.177948  |  Epoch 20  |  Training loss 0.408\n",
      "10:34:28.171670  |  Epoch 30  |  Training loss 0.335\n",
      "\n",
      "Validation accuracy: 85.24923702950153\n",
      "--------------------------------------------------\n",
      "Momentum: 0.85 \n",
      "Weight decay: 0.01 \n",
      "Learning rate: 0.001\n",
      "10:34:28.741307  |  Epoch 1  |  Training loss 0.688\n",
      "10:34:29.579912  |  Epoch 10  |  Training loss 0.477\n",
      "10:34:30.602394  |  Epoch 20  |  Training loss 0.423\n",
      "10:34:31.568474  |  Epoch 30  |  Training loss 0.363\n",
      "\n",
      "Validation accuracy: 84.02848423194304\n",
      "--------------------------------------------------\n",
      "Momentum: 0.9 \n",
      "Weight decay: 0 \n",
      "Learning rate: 0.001\n",
      "10:34:32.155905  |  Epoch 1  |  Training loss 0.685\n",
      "10:34:32.992355  |  Epoch 10  |  Training loss 0.443\n",
      "10:34:34.050544  |  Epoch 20  |  Training loss 0.340\n",
      "10:34:34.988018  |  Epoch 30  |  Training loss 0.268\n",
      "\n",
      "Validation accuracy: 88.09766022380468\n",
      "--------------------------------------------------\n",
      "Momentum: 0.9 \n",
      "Weight decay: 0.001 \n",
      "Learning rate: 0.001\n",
      "10:34:35.555947  |  Epoch 1  |  Training loss 0.685\n",
      "10:34:36.437029  |  Epoch 10  |  Training loss 0.444\n",
      "10:34:37.386314  |  Epoch 20  |  Training loss 0.342\n",
      "10:34:38.329164  |  Epoch 30  |  Training loss 0.271\n",
      "\n",
      "Validation accuracy: 88.09766022380468\n",
      "--------------------------------------------------\n",
      "Momentum: 0.9 \n",
      "Weight decay: 0.01 \n",
      "Learning rate: 0.001\n",
      "10:34:38.912443  |  Epoch 1  |  Training loss 0.685\n",
      "10:34:39.740595  |  Epoch 10  |  Training loss 0.452\n",
      "10:34:40.751397  |  Epoch 20  |  Training loss 0.369\n",
      "10:34:41.714083  |  Epoch 30  |  Training loss 0.297\n",
      "\n",
      "Validation accuracy: 86.87690742624619\n",
      "--------------------------------------------------\n",
      "Momentum: 0 \n",
      "Weight decay: 0 \n",
      "Learning rate: 0.01\n",
      "10:34:42.275602  |  Epoch 1  |  Training loss 0.683\n",
      "10:34:42.953470  |  Epoch 10  |  Training loss 0.444\n",
      "10:34:43.710927  |  Epoch 20  |  Training loss 0.349\n",
      "10:34:44.461181  |  Epoch 30  |  Training loss 0.286\n",
      "\n",
      "Validation accuracy: 88.19938962360122\n",
      "--------------------------------------------------\n",
      "Momentum: 0 \n",
      "Weight decay: 0.001 \n",
      "Learning rate: 0.01\n",
      "10:34:44.930784  |  Epoch 1  |  Training loss 0.683\n",
      "10:34:45.705985  |  Epoch 10  |  Training loss 0.445\n",
      "10:34:46.623417  |  Epoch 20  |  Training loss 0.352\n",
      "10:34:47.442101  |  Epoch 30  |  Training loss 0.288\n",
      "\n",
      "Validation accuracy: 87.99593082400814\n",
      "--------------------------------------------------\n",
      "Momentum: 0 \n",
      "Weight decay: 0.01 \n",
      "Learning rate: 0.01\n",
      "10:34:48.001559  |  Epoch 1  |  Training loss 0.683\n",
      "10:34:48.762705  |  Epoch 10  |  Training loss 0.452\n",
      "10:34:49.596135  |  Epoch 20  |  Training loss 0.376\n",
      "10:34:50.424926  |  Epoch 30  |  Training loss 0.312\n",
      "\n",
      "Validation accuracy: 87.18209562563581\n",
      "--------------------------------------------------\n",
      "Momentum: 0.85 \n",
      "Weight decay: 0 \n",
      "Learning rate: 0.01\n",
      "10:34:50.936223  |  Epoch 1  |  Training loss 0.600\n",
      "10:34:51.717931  |  Epoch 10  |  Training loss 0.275\n",
      "10:34:52.615577  |  Epoch 20  |  Training loss 0.208\n",
      "10:34:53.498094  |  Epoch 30  |  Training loss 0.156\n",
      "\n",
      "Validation accuracy: 91.45473041709053\n",
      "--------------------------------------------------\n",
      "Momentum: 0.85 \n",
      "Weight decay: 0.001 \n",
      "Learning rate: 0.01\n",
      "10:34:54.062219  |  Epoch 1  |  Training loss 0.600\n",
      "10:34:54.949588  |  Epoch 10  |  Training loss 0.279\n",
      "10:34:55.874390  |  Epoch 20  |  Training loss 0.214\n",
      "10:34:56.879963  |  Epoch 30  |  Training loss 0.184\n",
      "\n",
      "Validation accuracy: 91.8616480162767\n",
      "--------------------------------------------------\n",
      "Momentum: 0.85 \n",
      "Weight decay: 0.01 \n",
      "Learning rate: 0.01\n",
      "10:34:57.450083  |  Epoch 1  |  Training loss 0.604\n",
      "10:34:58.351262  |  Epoch 10  |  Training loss 0.304\n",
      "10:34:59.328034  |  Epoch 20  |  Training loss 0.263\n",
      "10:35:00.379845  |  Epoch 30  |  Training loss 0.256\n",
      "\n",
      "Validation accuracy: 89.72533062054934\n",
      "--------------------------------------------------\n",
      "Momentum: 0.9 \n",
      "Weight decay: 0 \n",
      "Learning rate: 0.01\n",
      "10:35:01.161329  |  Epoch 1  |  Training loss 0.587\n",
      "10:35:02.292767  |  Epoch 10  |  Training loss 0.283\n",
      "10:35:03.316148  |  Epoch 20  |  Training loss 0.204\n",
      "10:35:04.274623  |  Epoch 30  |  Training loss 0.167\n",
      "\n",
      "Validation accuracy: 90.64089521871821\n",
      "--------------------------------------------------\n",
      "Momentum: 0.9 \n",
      "Weight decay: 0.001 \n",
      "Learning rate: 0.01\n",
      "10:35:04.805600  |  Epoch 1  |  Training loss 0.587\n",
      "10:35:05.702823  |  Epoch 10  |  Training loss 0.288\n",
      "10:35:06.628235  |  Epoch 20  |  Training loss 0.222\n",
      "10:35:07.590534  |  Epoch 30  |  Training loss 0.178\n",
      "\n",
      "Validation accuracy: 91.25127161749745\n",
      "--------------------------------------------------\n",
      "Momentum: 0.9 \n",
      "Weight decay: 0.01 \n",
      "Learning rate: 0.01\n",
      "10:35:08.239297  |  Epoch 1  |  Training loss 0.590\n",
      "10:35:09.160663  |  Epoch 10  |  Training loss 0.311\n",
      "10:35:10.193190  |  Epoch 20  |  Training loss 0.279\n",
      "10:35:11.151725  |  Epoch 30  |  Training loss 0.295\n",
      "\n",
      "Validation accuracy: 87.69074262461851\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_settings = hyperparameter_testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Values for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after hyperparameter testing and choosing best model:\n",
      "\n",
      "Highest validation accuracy: 91.8616480162767 \n",
      "Momentum: 0.85 \n",
      "Weight decay: 0.001 \n",
      "Learning rate: 0.01\n"
     ]
    }
   ],
   "source": [
    "best_model = best_settings[\"Model\"]\n",
    "accuracy = best_settings[\"Accuracy\"]\n",
    "momentum = best_settings[\"Momentum\"]\n",
    "weight_decay = best_settings[\"Weight decay\"]\n",
    "learning_rate = best_settings[\"Learning rate\"]\n",
    "\n",
    "print(\"Results after hyperparameter testing and choosing best model:\\n\")\n",
    "print(f\"Highest validation accuracy: {accuracy} \\nMomentum: {momentum} \\nWeight decay: {weight_decay} \\nLearning rate: {learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of the model with learning rate: 0.01, Momentum: 0.85, Weight decay: 0.001 \n",
      "Test Accuracy: 91.45\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = compute_accuracy(best_model, test_loader)\n",
    "print(f\"Evaluation of the model with learning rate: {learning_rate}, Momentum: {momentum}, Weight decay: {weight_decay} \\nTest Accuracy: {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "INF265",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
